{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sender Output (Continuous): tensor([[ 0.6104, -0.1569, -0.1290, -0.6602, -0.7849,  0.3486, -0.7926, -0.1663,\n",
      "          0.0035,  0.2201,  1.1152, -0.6269, -0.0760, -1.2679,  0.3927, -0.2035]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Quantized Output: tensor([[ 0.0984,  0.0992,  0.0761, -0.0454, -0.0139, -0.0485, -0.0839,  0.0201,\n",
      "          0.0010,  0.0679,  0.0735, -0.0461, -0.0019, -0.0817,  0.0678,  0.0102]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Quantization Indices: tensor([30])\n",
      "Receiver Output: tensor([[0.0918]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from vector_quantize_pytorch import VectorQuantize\n",
    "\n",
    "vq_layer = VectorQuantize(\n",
    "    dim=16,                # dimension of the input features\n",
    "    codebook_size=32,      # number of possible discrete codes\n",
    "    decay=0.8              # decay for the exponential moving average in the codebook update\n",
    ")\n",
    "\n",
    "class Sender(nn.Module):\n",
    "    def __init__(self, input_dim=10, output_dim=16):\n",
    "        super(Sender, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "    \n",
    "class Receiver(nn.Module):\n",
    "    def __init__(self, input_dim=16, output_dim=1):\n",
    "        super(Receiver, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "sender = Sender()\n",
    "receiver = Receiver()\n",
    "input_data = torch.randn((1, 10))  # random input to the sender\n",
    "\n",
    "sender_output = sender(input_data)\n",
    "print(\"Sender Output (Continuous):\", sender_output)\n",
    "\n",
    "quantized_output, indices, _ = vq_layer(sender_output)\n",
    "print(\"Quantized Output:\", quantized_output)\n",
    "print(\"Quantization Indices:\", indices)\n",
    "\n",
    "receiver_output = receiver(quantized_output)\n",
    "print(\"Receiver Output:\", receiver_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from options import Options\n",
    "from archs.run_series import run_experiment\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from archs.network import GAT, Transform\n",
    "\n",
    "from archs.distractors import select_distractors\n",
    "\n",
    "code_book = 512\n",
    "\n",
    "class SenderRel(nn.Module):\n",
    "    def __init__(self, num_node_features, embedding_size, heads, layer, hidden_size, temperature):\n",
    "        super(SenderRel, self).__init__()\n",
    "        self.num_node_features = num_node_features\n",
    "        self.heads = heads\n",
    "        self.hidden_size = hidden_size\n",
    "        self.temp = temperature\n",
    "          \n",
    "        self.layer = Transform(self.num_node_features, embedding_size, heads) if layer == 'transform' else GAT(self.num_node_features, embedding_size, heads) \n",
    "        self.fc = nn.Linear(2 * embedding_size, hidden_size) \n",
    "\n",
    "        self.vq_layer = VectorQuantize(\n",
    "            dim = hidden_size,\n",
    "            codebook_size = code_book,\n",
    "            decay = 0.8\n",
    "        )\n",
    "\n",
    "    def forward(self, x, _aux_input):\n",
    "        data = _aux_input\n",
    "\n",
    "        batch_ptr, target_node_idx, ego_idx = data.ptr, data.target_node_idx, data.ego_node_idx\n",
    "\n",
    "        h = self.layer(data)\n",
    "\n",
    "        adjusted_ego_idx = ego_idx + batch_ptr[:-1]\n",
    "        adjusted_target_node_idx = target_node_idx + batch_ptr[:-1]\n",
    "  \n",
    "        target_embedding = torch.cat((h[adjusted_target_node_idx], h[adjusted_ego_idx]), dim=1) \n",
    "\n",
    "        output = self.fc(target_embedding)   \n",
    "\n",
    "        quantized_output, indices, _ = self.vq_layer(output)\n",
    "\n",
    "        return quantized_output # batch_size x hidden_size\n",
    "\n",
    "class ReceiverRel(nn.Module):\n",
    "    def __init__(self, num_node_features, embedding_size, heads, layer, hidden_size, distractors):\n",
    "        super(ReceiverRel, self).__init__()\n",
    "        self.num_node_features = num_node_features\n",
    "        self.heads = heads\n",
    "        self.distractors = distractors\n",
    "        \n",
    "        self.layer = Transform(self.num_node_features, embedding_size, heads) if layer == 'transform' else GAT(self.num_node_features, embedding_size, heads)\n",
    "        self.fc = nn.Linear(hidden_size, embedding_size)\n",
    "\n",
    "    def forward(self, message, _input, _aux_input):\n",
    "        data = _aux_input\n",
    "        h = self.layer(data)\n",
    "\n",
    "        indices, _ = select_distractors(\n",
    "            data, \n",
    "            self.distractors if not getattr(data, 'evaluation', False) else len(data.target_node) - 1,\n",
    "            evaluation=getattr(data, 'evaluation', False)\n",
    "        )\n",
    "\n",
    "        embeddings = h[indices]\n",
    "\n",
    "        batch_size = data.num_graphs\n",
    "        num_candidates = embeddings.size(0) // batch_size\n",
    "\n",
    "        embeddings = embeddings.view(batch_size, num_candidates, -1)\n",
    "        message = self.fc(message)\n",
    "        message = message.unsqueeze(2)  \n",
    "\n",
    "        dot_products = torch.bmm(embeddings, message).squeeze(-1)  \n",
    "        log_probabilities = F.log_softmax(dot_products, dim=1)\n",
    "\n",
    "        # add small random noise\n",
    "        log_probabilities = log_probabilities + 1e-10 * torch.randn_like(log_probabilities)\n",
    "        \n",
    "        return log_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: data/uniform\n",
      "epoch=1, mode=train, loss=1.6087253093719482, acc=0.2029999941587448\n",
      "epoch=1, mode=test, loss=1.6153666973114014, acc=0.19900000095367432\n",
      "epoch=2, mode=train, loss=1.4476107358932495, acc=0.32419997453689575\n",
      "epoch=2, mode=test, loss=1.5324656963348389, acc=0.3399999737739563\n",
      "epoch=3, mode=train, loss=1.2681119441986084, acc=0.3837999999523163\n",
      "epoch=3, mode=test, loss=1.3369066715240479, acc=0.39100003242492676\n",
      "epoch=4, mode=train, loss=1.193585991859436, acc=0.40539997816085815\n",
      "epoch=4, mode=test, loss=1.3519017696380615, acc=0.3619999885559082\n",
      "epoch=5, mode=train, loss=1.1216416358947754, acc=0.4431999921798706, eval_acc=0.03125, complexity=0, information_loss=0\n",
      "epoch=5, mode=test, loss=1.425414800643921, acc=0.3720000088214874\n",
      "epoch=6, mode=train, loss=1.0616799592971802, acc=0.47540000081062317\n",
      "epoch=6, mode=test, loss=0.9986928701400757, acc=0.5010000467300415\n",
      "epoch=7, mode=train, loss=0.9840986728668213, acc=0.5248000025749207\n",
      "epoch=7, mode=test, loss=0.9942881464958191, acc=0.4790000021457672\n",
      "epoch=8, mode=train, loss=0.9426948428153992, acc=0.534000039100647\n",
      "epoch=8, mode=test, loss=0.929310142993927, acc=0.5080000162124634\n",
      "epoch=9, mode=train, loss=0.9044103026390076, acc=0.527999997138977\n",
      "epoch=9, mode=test, loss=0.8665351867675781, acc=0.5430000424385071\n",
      "epoch=10, mode=train, loss=0.86781907081604, acc=0.5493999719619751, eval_acc=0.15625, complexity=0, information_loss=0\n",
      "epoch=10, mode=test, loss=0.8853636980056763, acc=0.527999997138977\n"
     ]
    }
   ],
   "source": [
    "options_input = Options(n_epochs=10, distractors=4, prune_graph=True)\n",
    "results = run_experiment(options_input, f'results/{options_input.need_probs}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kinship",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
