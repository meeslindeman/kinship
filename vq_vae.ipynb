{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sender Output (Continuous): tensor([[ 0.2297, -0.0911, -0.9183,  0.9135,  0.6772, -1.4203, -0.7435, -0.0276,\n",
      "         -0.1114, -0.2450, -0.7967, -0.2640, -1.5369, -0.3758,  0.2145,  1.5033]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Quantized Output: tensor([[ 0.0656, -0.0100, -0.0638,  0.1032, -0.0405, -0.0616, -0.0976,  0.0048,\n",
      "          0.0480,  0.0240,  0.0214, -0.0821, -0.1011,  0.0019,  0.0987,  0.0625]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Quantization Indices: tensor([22])\n",
      "Test: tensor([0.5808], grad_fn=<AddBackward0>)\n",
      "Receiver Output: tensor([[-0.1836]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from vector_quantize_pytorch import VectorQuantize\n",
    "\n",
    "vq_layer = VectorQuantize(\n",
    "    dim=16,                # dimension of the input features\n",
    "    codebook_size=32,      # number of possible discrete codes\n",
    "    decay=0.8              # decay for the exponential moving average in the codebook update\n",
    ")\n",
    "\n",
    "class Sender(nn.Module):\n",
    "    def __init__(self, input_dim=10, output_dim=16):\n",
    "        super(Sender, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "    \n",
    "class Receiver(nn.Module):\n",
    "    def __init__(self, input_dim=16, output_dim=1):\n",
    "        super(Receiver, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "sender = Sender()\n",
    "receiver = Receiver()\n",
    "input_data = torch.randn((1, 10))  # random input to the sender\n",
    "\n",
    "sender_output = sender(input_data)\n",
    "print(\"Sender Output (Continuous):\", sender_output)\n",
    "\n",
    "quantized_output, indices, commit_loss = vq_layer(sender_output)\n",
    "print(\"Quantized Output:\", quantized_output)\n",
    "print(\"Quantization Indices:\", indices)\n",
    "print(\"Test:\", commit_loss)\n",
    "\n",
    "receiver_output = receiver(quantized_output)\n",
    "print(\"Receiver Output:\", receiver_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from options import Options\n",
    "from archs.run_series import run_experiment\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from archs.network import GAT, Transform\n",
    "\n",
    "from archs.distractors import select_distractors\n",
    "\n",
    "code_book = 512\n",
    "\n",
    "class SenderRel(nn.Module):\n",
    "    def __init__(self, num_node_features, embedding_size, heads, layer, hidden_size, temperature):\n",
    "        super(SenderRel, self).__init__()\n",
    "        self.num_node_features = num_node_features\n",
    "        self.heads = heads\n",
    "        self.hidden_size = hidden_size\n",
    "        self.temp = temperature\n",
    "          \n",
    "        self.layer = Transform(self.num_node_features, embedding_size, heads) if layer == 'transform' else GAT(self.num_node_features, embedding_size, heads) \n",
    "        self.fc = nn.Linear(2 * embedding_size, hidden_size) \n",
    "\n",
    "        self.vq_layer = VectorQuantize(\n",
    "            dim = hidden_size,\n",
    "            codebook_size = code_book,\n",
    "            decay = 0.8\n",
    "        )\n",
    "\n",
    "    def forward(self, x, _aux_input):\n",
    "        data = _aux_input\n",
    "\n",
    "        batch_ptr, target_node_idx, ego_idx = data.ptr, data.target_node_idx, data.ego_node_idx\n",
    "\n",
    "        h = self.layer(data)\n",
    "\n",
    "        adjusted_ego_idx = ego_idx + batch_ptr[:-1]\n",
    "        adjusted_target_node_idx = target_node_idx + batch_ptr[:-1]\n",
    "  \n",
    "        target_embedding = torch.cat((h[adjusted_target_node_idx], h[adjusted_ego_idx]), dim=1) \n",
    "\n",
    "        output = self.fc(target_embedding)   \n",
    "\n",
    "        quantized_output, indices, _ = self.vq_layer(output)\n",
    "\n",
    "        return quantized_output # batch_size x hidden_size\n",
    "\n",
    "class ReceiverRel(nn.Module):\n",
    "    def __init__(self, num_node_features, embedding_size, heads, layer, hidden_size, distractors):\n",
    "        super(ReceiverRel, self).__init__()\n",
    "        self.num_node_features = num_node_features\n",
    "        self.heads = heads\n",
    "        self.distractors = distractors\n",
    "        \n",
    "        self.layer = Transform(self.num_node_features, embedding_size, heads) if layer == 'transform' else GAT(self.num_node_features, embedding_size, heads)\n",
    "        self.fc = nn.Linear(hidden_size, embedding_size)\n",
    "\n",
    "    def forward(self, message, _input, _aux_input):\n",
    "        data = _aux_input\n",
    "        h = self.layer(data)\n",
    "\n",
    "        indices, _ = select_distractors(\n",
    "            data, \n",
    "            self.distractors if not getattr(data, 'evaluation', False) else len(data.target_node) - 1,\n",
    "            evaluation=getattr(data, 'evaluation', False)\n",
    "        )\n",
    "\n",
    "        embeddings = h[indices]\n",
    "\n",
    "        batch_size = data.num_graphs\n",
    "        num_candidates = embeddings.size(0) // batch_size\n",
    "\n",
    "        embeddings = embeddings.view(batch_size, num_candidates, -1)\n",
    "        message = self.fc(message)\n",
    "        message = message.unsqueeze(2)  \n",
    "\n",
    "        dot_products = torch.bmm(embeddings, message).squeeze(-1)  \n",
    "        log_probabilities = F.log_softmax(dot_products, dim=1)\n",
    "\n",
    "        # add small random noise\n",
    "        log_probabilities = log_probabilities + 1e-10 * torch.randn_like(log_probabilities)\n",
    "        \n",
    "        return log_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: data/uniform\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m options_input \u001b[38;5;241m=\u001b[39m Options(n_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, distractors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, prune_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresults/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43moptions_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneed_probs\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Thesis/kinship/archs/run_series.py:46\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(opts, target_folder, save)\u001b[0m\n\u001b[1;32m     44\u001b[0m train_loader, valid_loader, eval_loader \u001b[38;5;241m=\u001b[39m get_loaders(opts, dataset)\n\u001b[1;32m     45\u001b[0m game \u001b[38;5;241m=\u001b[39m get_game(opts, dataset\u001b[38;5;241m.\u001b[39mnum_node_features)\n\u001b[0;32m---> 46\u001b[0m results, trainer \u001b[38;5;241m=\u001b[39m \u001b[43mperform_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m metrics_df, counts_df, evaluation_df \u001b[38;5;241m=\u001b[39m results_to_dataframes(results, opts, target_folder, save)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opts\u001b[38;5;241m.\u001b[39mlog_wandb:\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Thesis/kinship/archs/train.py:24\u001b[0m, in \u001b[0;36mperform_training\u001b[0;34m(opts, train_loader, val_loader, eval_loader, game)\u001b[0m\n\u001b[1;32m     14\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(game\u001b[38;5;241m.\u001b[39mparameters())\n\u001b[1;32m     16\u001b[0m trainer \u001b[38;5;241m=\u001b[39m core\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m     17\u001b[0m     game\u001b[38;5;241m=\u001b[39mgame,\n\u001b[1;32m     18\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[callbacks]\n\u001b[1;32m     22\u001b[0m )\n\u001b[0;32m---> 24\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m core\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     27\u001b[0m results \u001b[38;5;241m=\u001b[39m callbacks\u001b[38;5;241m.\u001b[39mget_results()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kinship/lib/python3.12/site-packages/egg/core/trainers.py:273\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, n_epochs)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    271\u001b[0m     callback\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 273\u001b[0m train_loss, train_interaction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    276\u001b[0m     callback\u001b[38;5;241m.\u001b[39mon_epoch_end(train_loss, train_interaction, epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kinship/lib/python3.12/site-packages/egg/core/trainers.py:216\u001b[0m, in \u001b[0;36mTrainer.train_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    214\u001b[0m context \u001b[38;5;241m=\u001b[39m autocast() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;28;01melse\u001b[39;00m nullcontext()\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context:\n\u001b[0;32m--> 216\u001b[0m     optimized_loss, interaction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgame\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_freq \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;66;03m# throughout EGG, we minimize _mean_ loss, not sum\u001b[39;00m\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;66;03m# hence, we need to account for that when aggregating grads\u001b[39;00m\n\u001b[1;32m    221\u001b[0m         optimized_loss \u001b[38;5;241m=\u001b[39m optimized_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_freq\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kinship/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kinship/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Thesis/kinship/archs/lexicon_agent_wrapper.py:152\u001b[0m, in \u001b[0;36mLexiconSenderReceiverGS.forward\u001b[0;34m(self, sender_input, labels, receiver_input, aux_input)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, sender_input, labels, receiver_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, aux_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# if self.count == 10000:\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;66;03m#     self.warm_up = False\u001b[39;00m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;66;03m#     print('finetune')\u001b[39;00m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;66;03m# self.count += 1\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarm_up \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m(\u001b[49m\u001b[43msender_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maux_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_up\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarm_up\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m     receiver_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreceiver(message, receiver_input, aux_input, warm_up\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarm_up)\n\u001b[1;32m    155\u001b[0m     loss, aux \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(\n\u001b[1;32m    156\u001b[0m         sender_input,\n\u001b[1;32m    157\u001b[0m         message,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    161\u001b[0m         aux_input,\n\u001b[1;32m    162\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kinship/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kinship/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Thesis/kinship/archs/lexicon_agent_wrapper.py:33\u001b[0m, in \u001b[0;36mLexiconSenderWrapper.forward\u001b[0;34m(self, x, aux_input, warm_up)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m h\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgs\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 33\u001b[0m     lex_logit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlex_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m warm_up:\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kinship/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kinship/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kinship/lib/python3.12/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not tuple"
     ]
    }
   ],
   "source": [
    "options_input = Options(n_epochs=10, distractors=4, prune_graph=True)\n",
    "results = run_experiment(options_input, f'results/{options_input.need_probs}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kinship",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
